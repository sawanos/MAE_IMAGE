{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda.amp\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import util.lr_sched as lr_sched\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "import timm.optim.optim_factory as optim_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.rand(100, 1, 224,224)\n",
    "y_train = torch.rand(100)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean, std取得\n",
    "def get_mean_and_std(x_train):\n",
    "    mean = x_train.mean(axis = (0,2,3)) #(B, 3, 512, 512 ) (3, *****)\n",
    "    std = x_train.std(axis = (0,2,3))\n",
    "    return mean, std\n",
    "mean, std = get_mean_and_std(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, y_train, mean = 0., std = 1.):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "        \n",
    "#         # 標準化\n",
    "#         if isinstance(self.mean, (float, int)):\n",
    "#             self.x_train -= self.mean\n",
    "#         else:\n",
    "#             self.x_train -= self.mean.reshape(1, 3, 1, 1)\n",
    "        \n",
    "#         if isinstance(self.std, (float, int)):\n",
    "#             self.x_train /= self.std\n",
    "#         else:\n",
    "#             self.x_train /= self.std.reshape(1, 3, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         x = torch.cat((self.x_train[idx], self.x_train[idx], self.x_train[idx]),0) #(3, 224, 224)へ\n",
    "\n",
    "#         return self.x_train[idx].to(dtype=torch.float), self.y_train[idx]\n",
    "         return x.to(dtype=torch.float), self.y_train[idx]\n",
    "\n",
    "train_data = make_dataset(x_train, y_train, mean = mean, std = std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.__getitem__(19)[0]\n",
    "print(x.shape)\n",
    "x = x.permute(1, 2, 0)\n",
    "plt.imshow(x.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_ids = [0, 1, 2, 3]\n",
    "device = torch.device(f\"cuda:{gpu_ids[0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, num_workers = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_MAE\n",
    "import model_mae \n",
    "\n",
    "model_mae = model_mae.__dict__['mae_vit_large_patch16'](norm_pix_loss='store_true')\n",
    "\n",
    "model_mae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effe_batch_size = batch_size * accum_iter * # gpus'\n",
    "lr = 1e-3 * (batch_size*len(gpu_ids)) / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = optim_factory.add_weight_decay(model_mae, 0.05)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=(0.9, 0.95))\n",
    "loss_scaler = NativeScaler()\n",
    "accum_iter = 1 #default 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(df,log_csv_path,**kwargs):\n",
    "#     print(df.head())\n",
    "    df = pd.concat([df,pd.DataFrame.from_dict([kwargs])])\n",
    "#     print(df.head())\n",
    "    df.to_csv(log_csv_path,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = 0.75\n",
    "n_epochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = 0.75\n",
    "n_epochs = 800\n",
    "\n",
    "# 学習\n",
    "train_loss = []\n",
    "\n",
    "log_csv_path = \"./models/log.csv\"\n",
    "df = pd.DataFrame()\n",
    "# df.to_csv(log_csv_path)\n",
    "start_time = time.time()\n",
    "\n",
    "model_mae.train()\n",
    "model = torch.nn.DataParallel(model_mae, [0, 1, 2, 3])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    \n",
    "    n_train = 0\n",
    "    total_loss_train = 0\n",
    "    \n",
    "    optimizer.zero_grad()  # 勾配の初期化→MAEではエポックごとに初期化しいている\n",
    "    \n",
    "    for data_iter_step, (x, _) in tqdm(enumerate(dataloader_train)):\n",
    "        \n",
    "        n_batch = x.shape[0]\n",
    "        \n",
    "        #iter毎にLr_scheを使用\n",
    "        if data_iter_step % accum_iter == 0:\n",
    "            lr_sched.adjust_learning_rate(optimizer, data_iter_step / len(dataloader_train) + epoch)\n",
    "        \n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        \n",
    "        #MAEにデータを入力\n",
    "        #ampを使用\n",
    "        with  torch.cuda.amp.autocast():\n",
    "            loss, pred, mask = model(x, mask_ratio=mask_ratio)\n",
    "            \n",
    "        print(loss.shape)\n",
    "        print(pred.shape)\n",
    "        print(mask.shape)\n",
    "        loss = loss.sum()\n",
    "           \n",
    "        # 誤差の逆伝播+# パラメータの更新がloss_scalerに含まている\n",
    "        loss /= accum_iter\n",
    "        loss_scaler(loss, optimizer, parameters=model.parameters(),\n",
    "                    update_grad=(data_iter_step + 1) % accum_iter == 0)\n",
    "        if (data_iter_step + 1) % accum_iter == 0:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss_train += loss.item() * n_batch\n",
    "        n_train += n_batch\n",
    "\n",
    "    train_loss.append(total_loss_train / n_train)\n",
    "    \n",
    "    \n",
    "#     if epoch % 20 == 0 or epoch + 1 == n_epochs:\n",
    "#         torch.save(model.module.state_dict(), f\"./models/{epoch}.pt\")\n",
    "\n",
    "    print('EPOCH: {}, Train_loss {:.3f}'.format(\n",
    "        epoch,\n",
    "        total_loss_train / n_train\n",
    "    ))\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "    \n",
    "    df = write_out(df,log_csv_path,epoch=epoch,train_loss=train_loss, train_time = total_time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#視覚化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習済みモデルの取り込み\n",
    "import model_mae\n",
    "model_mae = model_mae.__dict__['mae_vit_large_patch16'](norm_pix_loss='store_true')\n",
    "model_mae.load_state_dict(torch.load('models/400.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x.detach().numpy()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the utils\n",
    "\n",
    "imagenet_mean = np.array([mean, mean, mean])\n",
    "imagenet_std = np.array([std, std, std])\n",
    "\n",
    "def show_image(image, title=''):\n",
    "    # image is [H, W, 3]\n",
    "    assert image.shape[2] == 3\n",
    "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n",
    "    # build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model):\n",
    "    x = torch.tensor(img)\n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio=0.75)\n",
    "    y = model.unpatchify(y)\n",
    "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "    \n",
    "    x = torch.einsum('nchw->nhwc', x)\n",
    "    \n",
    "       # masked image\n",
    "    im_masked = x * (1 - mask)\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = x * (1 - mask) + y * mask\n",
    "\n",
    "    # make the plt figure larger\n",
    "    plt.rcParams['figure.figsize'] = [24, 24]\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    show_image(x[0], \"original\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    show_image(im_masked[0], \"masked\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    show_image(y[0], \"reconstruction\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    show_image(im_paste[0], \"reconstruction + visible\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "print('MAE with pixel reconstruction:')\n",
    "run_one_image(img, model_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
